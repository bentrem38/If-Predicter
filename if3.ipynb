{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoModelForSeq2SeqLM\n",
    "from transformers import RobertaTokenizer\n",
    "from datasets import DatasetDict\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "from datasets import Dataset\n",
    "import autopep8\n",
    "import sacrebleu\n",
    "import codebleu\n",
    "import os\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import evaluate\n",
    "from codebleu import calc_codebleu\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 1. Install Required Libraries\n",
    "# ------------------------\n",
    "#!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
    "#!pip install transformers datasets evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['cleaned_method', 'target_block', 'tokens_in_method'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['cleaned_method', 'target_block', 'tokens_in_method'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['cleaned_method', 'target_block', 'tokens_in_method'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#https://huggingface.co/Salesforce/codet5-small\n",
    "# ------------------------------------------------------------------------\n",
    "# 2. Load Dataset (CodeXGLUE - Code Translation Java <=> C#)\n",
    "# ------------------------------------------------------------------------\n",
    "data_dir = r\"C:\\Users\\bentr\\Downloads\\Archive\\Archive\"\n",
    "\n",
    "# CodeXGLUE is a benchmark dataset collection by Microsoft for code-related tasks.\n",
    "# Here, we use the code-translation-python-java dataset.\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "# Read the CSV files into DataFrames\n",
    "test_dataset = load_dataset('csv', data_files=os.path.join(data_dir, csv_files[0]))['train']\n",
    "train_dataset = load_dataset('csv', data_files=os.path.join(data_dir, csv_files[1]))['train']\n",
    "validation_dataset = load_dataset('csv', data_files=os.path.join(data_dir, csv_files[2]))['train']\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'test': test_dataset,\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset\n",
    "})\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32101, 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"Salesforce/codet5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.add_tokens([\"<MASK>\"]) #Imagine we need an extra token. This line adds the extra token to the vocabulary\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 250\n",
      "Processed 500\n",
      "499\n",
      "1\n",
      "Processed 250\n",
      "Processed 500\n",
      "500\n",
      "0\n",
      "Processed 250\n",
      "Processed 500\n",
      "Processed 750\n",
      "Processed 1000\n",
      "Processed 1250\n",
      "Processed 1500\n",
      "Processed 1750\n",
      "Processed 2000\n",
      "Processed 2250\n",
      "Processed 2500\n",
      "2499\n",
      "1\n",
      "Dataset({\n",
      "    features: ['processed_target', 'processed_method'],\n",
      "    num_rows: 499\n",
      "})\n",
      "Dataset({\n",
      "    features: ['processed_target', 'processed_method'],\n",
      "    num_rows: 2499\n",
      "})\n",
      "Dataset({\n",
      "    features: ['processed_target', 'processed_method'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def mask_dataset(dataset, datatype):\n",
    "    if datatype == \"test\" or \"validation\": max = 499\n",
    "    if datatype == \"train\": max = 2499\n",
    "    processed_methods = []\n",
    "    processed_targets = []\n",
    "    i = 0\n",
    "\n",
    "    # Loop through the dataset and apply processing\n",
    "    yes = 0\n",
    "    no = 0\n",
    "    while i <= max:\n",
    "        # Get the current method and target block\n",
    "            if (i + 1) % 250 == 0: print(f\"Processed {i + 1}\")\n",
    "            flattened_method = dataset[datatype][\"cleaned_method\"][i]\n",
    "            target = dataset[datatype][\"target_block\"][i]\n",
    "\n",
    "        # Flatten the method by joining words with a single space\n",
    "            flattened_method = \" \".join(flattened_method.split())\n",
    "            flattened_method = re.sub(r'\\s*([=+\\-*/%<>!&|^(),:{}\\[\\].])\\s*', r'\\1', flattened_method)\n",
    "\n",
    "        # Normalize the target block\n",
    "            target = re.sub(r'\\s*([=+\\-*/%<>!&|^(),:{}\\[\\].])\\s*', r'\\1', target)\n",
    "\n",
    "        # Replace target with <MASK> in the flattened method\n",
    "            if target not in flattened_method:\n",
    "                no+=1\n",
    "            if target in flattened_method:\n",
    "                flattened_method = flattened_method.replace(target, \"<MASK>\")\n",
    "                yes+=1\n",
    "                processed_methods.append(flattened_method)\n",
    "                processed_targets.append(target)\n",
    "        # Append processed results\n",
    "            i += 1\n",
    "    print(yes)\n",
    "    print(no)\n",
    "    # Build Dataset (not DatasetDict)\n",
    "    processed = Dataset.from_dict({\n",
    "        'processed_target': processed_targets,\n",
    "        'processed_method': processed_methods,\n",
    "    })\n",
    "    return processed\n",
    "valid = mask_dataset(dataset, \"validation\")\n",
    "test = mask_dataset(dataset, \"test\")\n",
    "train = mask_dataset(dataset, \"train\")\n",
    "print(valid)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size: 499\n",
      "Test size: 500\n",
      "Train size: 2499\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation size:\", len(valid))\n",
    "print(\"Test size:\", len(test))\n",
    "print(\"Train size:\", len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2499/2499 [00:02<00:00, 1066.36 examples/s]\n",
      "Map: 100%|██████████| 499/499 [00:00<00:00, 1005.82 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 980.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['processed_target', 'processed_method', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 499\n",
      "})\n",
      "Dataset({\n",
      "    features: ['processed_target', 'processed_method', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2499\n",
      "})\n",
      "Dataset({\n",
      "    features: ['processed_target', 'processed_method', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(dataset):\n",
    "    inputs = dataset[\"processed_method\"]\n",
    "    targets = dataset[\"processed_target\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=256, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=256, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "\n",
    "train = train.map(preprocess_function, batched=True)\n",
    "valid = valid.map(preprocess_function, batched = True)\n",
    "test = test.map(preprocess_function, batched = True)\n",
    "print(valid)\n",
    "print(train)\n",
    "print(test)\n",
    "#print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "dfv = valid.to_pandas()\n",
    "dftr = train.to_pandas()\n",
    "dft = test.to_pandas()\n",
    "# Save to CSV\n",
    "dftr.to_csv(\"maskedtrain3_dataset.csv\", index=False)\n",
    "dft.to_csv(\"maskedtest3_dataset.csv\", index=False)\n",
    "dfv.to_csv(\"maskedvalid3_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = Dataset.from_pandas(pd.read_csv(\"maskedvalid_dataset.csv\"))\n",
    "train = Dataset.from_pandas(pd.read_csv(\"maskedtrain_dataset.csv\"))\n",
    "test = Dataset.from_pandas(pd.read_csv(\"maskedtest_dataset.csv\"))\n",
    "print(valid)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bentr\\AppData\\Local\\Temp\\ipykernel_8304\\328619286.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 5. Define Training Arguments and Trainer\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./codet5-finetuned2\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=valid,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/6250 07:54 < 01:58, 10.52 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.045173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.043920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.045080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.045139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.04956385655403137, metrics={'train_runtime': 475.8947, 'train_samples_per_second': 26.256, 'train_steps_per_second': 13.133, 'total_flos': 676438323757056.0, 'train_loss': 0.04956385655403137, 'epoch': 4.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------\n",
    "# 6. Train the Model\n",
    "# ------------------------\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./codet5-small-finetuned2\\\\tokenizer_config.json',\n",
       " './codet5-small-finetuned2\\\\special_tokens_map.json',\n",
       " './codet5-small-finetuned2\\\\vocab.json',\n",
       " './codet5-small-finetuned2\\\\merges.txt',\n",
       " './codet5-small-finetuned2\\\\added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"./codet5-small-finetuned2\"\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(save_path)\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"./codet5-small-finetuned2\"\n",
    "# Load the saved model\n",
    "model = T5ForConditionalGeneration.from_pretrained(save_path)\n",
    "\n",
    "# Load the saved tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if ignore_timeouts and is_timeout(e):\n",
      "Generated If Statement:\n",
      " if ignore_timeouts and is_timeout(e):\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# 8. Test Code Translation\n",
    "# ------------------------\n",
    "input_code = test[\"processed_method\"][0]\n",
    "print(test[\"processed_target\"][0])\n",
    "inputs = tokenizer(input_code, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model.generate(**inputs, max_length=256)\n",
    "print(\"Generated If Statement:\\n\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: def read(self,count=True,timeout=None,ignore_non_errors=True,ignore_timeouts=True):try:return self._read(count,timeout)except usb.USBError as e:if DEBUG_COMM:log.info(\"read:e.errno=%s e.strerror=%s e.message=%s repr=%s\"%(e.errno,e.strerror,e.message,repr(e)))<MASK>return[]if ignore_non_errors and is_noerr(e):return[]raise\n",
      "Prediction: if ignore_timeouts and is_timeout(e):\n",
      "\n",
      "Input: def _cache_mem(curr_out,prev_mem,mem_len,reuse_len=None):\"\"\"cache hidden states into memory.\"\"\" if mem_len is None or mem_len==0:return None else:if reuse_len is not None and reuse_len>0:curr_out=curr_out[:reuse_len]<MASK>new_mem=curr_out[-mem_len:]else:new_mem=tf.concat([prev_mem,curr_out],0)[-mem_len:]new_mem.stop_gradient=True return new_mem\n",
      "Prediction: if prev_mem is None:\n",
      "\n",
      "Input: def filtered(gen):for example in gen:example_len=length_fn(example)# Checking max length boundary.if max_length is not None:<MASK>continue # Checking min length boundary.if min_length is not None:if example_len<min_length:continue # Within bounds.yield example\n",
      "Prediction: if example_len>max_length:\n",
      "\n",
      "Input: def search(self,query):# \"Search.ashx?query=\"+query+filterVal if not query:logger.debug(\"Empty search query\")return[]logger.debug('Searching TuneIn for \"%s\"'%query)args=\"&query=\"+query search_results=self._tunein(\"Search.ashx\",args)results=[]for item in self._flatten(search_results):<MASK># Only return stations self._stations[item[\"guide_id\"]]=item results.append(item)return results\n",
      "Prediction: if item[\"guide_id\"]!=\"station\":\n",
      "\n",
      "Input: def _check_script(self,script,directive):for var in compile_script(script):<MASK># Skip variable checks return False if var.can_contain(\".\"):# Yay!Our variable can contain any symbols!reason=('At least variable \"${var}\" can contain untrusted user input'.format(var=var.name))self.add_issue(directive=[directive]+var.providers,reason=reason)return True return False\n",
      "Prediction: if var.name in directive:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_inputs = test[\"processed_method\"]\n",
    "batch_size = 8  # start small, increase if your GPU can handle it\n",
    "decoded_outputs = []\n",
    "\n",
    "for i in tqdm(range(0, len(all_inputs), batch_size)):\n",
    "    batch = all_inputs[i:i+batch_size]\n",
    "\n",
    "    # Tokenize batch\n",
    "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=256)\n",
    "\n",
    "    # Decode each output\n",
    "    decoded_batch = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    decoded_outputs.extend(decoded_batch)\n",
    "\n",
    "# Optional: print a few outputs\n",
    "for i in range(5):\n",
    "\n",
    "    print(f\"\\nInput: {all_inputs[i]}\")\n",
    "    print(f\"Prediction: {decoded_outputs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(decoded_outputs))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdecoded_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1400\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(len(decoded_outputs))\n",
    "print(decoded_outputs[1400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = decoded_outputs\n",
    "references = test[\"processed_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SacreBLEU Score:  {'bleu': 0.35858156554860066, 'precisions': [0.6691988950276243, 0.43314255983350675, 0.35167464114832536, 0.2945518453427065], 'brevity_penalty': 0.8614215659736089, 'length_ratio': 0.8701923076923077, 'translation_length': 4344, 'reference_length': 4992}\n",
      "{'codebleu': 0.2178627681932208, 'ngram_match_score': 0.16532385593454665, 'weighted_ngram_match_score': 0.176943220007281, 'syntax_match_score': 0.36447811447811446, 'dataflow_match_score': 0.16470588235294117}\n",
      "500\n",
      "500\n",
      "Exact Match Score: 0.21\n"
     ]
    }
   ],
   "source": [
    "# Evaluate \n",
    "bleu = evaluate.load(\"bleu\")\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "print(\"SacreBLEU Score: \", results)\n",
    "language = \"python\"\n",
    "# Compute CodeBLEU\n",
    "#score = calc_codebleu(references, predictions, language)\n",
    "#print(\"CodeBLEU Score: \", score)\n",
    "res = calc_codebleu([[ref] for ref in references], predictions, lang=\"python\")\n",
    "print(res)\n",
    "\"\"\"\n",
    "SacreBLEU Score:  {'bleu': 0.8265168183793802, 'precisions': [0.9166666666666666, 0.8181818181818182, 0.8, 0.7777777777777778], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 12, 'reference_length': 12}\n",
    "['def sum(a, b): return a + b']\n",
    "['def add(a, b): return a + b']\n",
    "{'codebleu': 0.8251908791628888, 'ngram_match_score': 0.6434588841607617, 'weighted_ngram_match_score': 0.6573046324907937, 'syntax_match_score': 1.0, 'dataflow_match_score': 1.0}\n",
    "Exact Match Score: 0.00\n",
    "\"\"\"\n",
    "print(len(predictions))\n",
    "print(len(references))\n",
    "exact_match_score = np.mean([ref == pred for ref, pred in zip(references, predictions)])\n",
    "print(f\"Exact Match Score: {exact_match_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
